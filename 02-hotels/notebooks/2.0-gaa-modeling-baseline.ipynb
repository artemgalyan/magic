{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPES = {\n",
    "    'date_time': 'string',\n",
    "    'site_name': 'uint8',\n",
    "    'posa_continent': 'uint8',\n",
    "    'user_location_country': 'uint8',\n",
    "    'user_location_region': 'uint16',\n",
    "    'user_location_city': 'uint16',\n",
    "    'orig_destination_distance': 'float32',\n",
    "    'user_id': 'uint32',\n",
    "    'is_mobile': 'bool',\n",
    "    'is_package': 'bool',\n",
    "    'channel': 'uint8',\n",
    "    'srch_ci': 'string',\n",
    "    'srch_co': 'string',\n",
    "    'srch_adults_cnt': 'uint8',\n",
    "    'srch_children_cnt': 'uint8',\n",
    "    'srch_rm_cnt': 'uint8',\n",
    "    'srch_destination_id': 'uint16',\n",
    "    'srch_destination_type_id': 'uint8',\n",
    "    'is_booking': 'bool',\n",
    "    'cnt': 'uint16',\n",
    "    'hotel_continent': 'uint8',\n",
    "    'hotel_country': 'uint8',\n",
    "    'hotel_market': 'uint16',\n",
    "    'hotel_cluster': 'uint8',\n",
    "}\n",
    "DATETIME_COLUMNS = ['date_time', 'srch_ci', 'srch_co']\n",
    "BOOLEAN_COLUMNS = ['is_booking', 'is_mobile', 'is_package']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyoma\\AppData\\Local\\Temp\\ipykernel_14592\\3881431213.py:22: DeprecationWarning: `replace` is deprecated. DataFrame.replace is deprecated and will be removed in a future version. Please use\n",
      "    df = df.with_columns(new_column.alias(column_name))\n",
      "instead.\n",
      "  df = df.replace(col, df[col] == 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def map_to_polars(dtype: str):\n",
    "    conversion = {\n",
    "        'string': pl.String,\n",
    "        'uint8': pl.UInt8,\n",
    "        'uint16': pl.UInt16,\n",
    "        'uint32': pl.UInt32,\n",
    "        'float32': pl.Float32,\n",
    "        'bool': pl.UInt8 \n",
    "    }\n",
    "    return conversion[dtype]\n",
    "\n",
    "dtypes = {k: map_to_polars(v) for k, v in DTYPES.items()}\n",
    "df = pl.read_csv('../data/raw/train.csv', dtypes=dtypes)\n",
    "df = df.with_columns(\n",
    "    *[pl.col(col).str.to_datetime() for col in DATETIME_COLUMNS]\n",
    ")\n",
    "for col in BOOLEAN_COLUMNS:\n",
    "    df = df.replace(col, df[col] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'is_booking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    co_ci_diff=(pl.col('srch_co') - pl.col('srch_ci')).dt.total_days().cast(pl.Int16),\n",
    "    ci_dt_diff=(pl.col('srch_ci') - pl.col('date_time')).dt.total_days().cast(pl.Int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [column for column in df.columns if df[column].dtype not in [pl.Boolean, pl.String, pl.Datetime]]\n",
    "categorical_columns = [column for column in df.columns if df[column].dtype in [pl.Boolean, pl.String]]\n",
    "str_columns = [column for column in df.columns if df[column].dtype == pl.String]\n",
    "datetime_columns = [column for column in df.columns if column not in numerical_columns and column not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['date_time'] + numerical_columns + categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(TARGET)\n",
    "y = data[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "Metric = Callable[[pl.DataFrame, pl.DataFrame, BaseEstimator], float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from math import floor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def get_interval(start: datetime, end: datetime, dt_column: pl.Series) -> pl.Series:\n",
    "    return (dt_column >= start) & (dt_column < end)\n",
    "\n",
    "def handle_nans(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[df.isna()] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "def blocked_cross_validation(\n",
    "    start: datetime,\n",
    "    end: datetime,\n",
    "    training_interval_len: timedelta,\n",
    "    test_interval_len: timedelta,\n",
    "    estimator: BaseEstimator,\n",
    "    x: pl.DataFrame,\n",
    "    y: pl.DataFrame,\n",
    "    dt_column: pl.Series,\n",
    "    metrics: dict[str, Metric]\n",
    ") -> tuple[dict[str, list[float]], list[BaseEstimator]]:\n",
    "    result_metrics = {key: [] for key in metrics.keys()}\n",
    "    estimators = []\n",
    "    n_intervals = floor((end - test_interval_len - start) / training_interval_len)\n",
    "\n",
    "    for i in tqdm(range(n_intervals - 1)):\n",
    "        est = clone(estimator)\n",
    "        training_dt_interval = start + i * training_interval_len, start + (i + 1) * training_interval_len\n",
    "        test_dt_interval = training_dt_interval[-1], training_dt_interval[-1] + test_interval_len\n",
    "        training_interval = get_interval(*training_dt_interval, dt_column)\n",
    "        test_interval = get_interval(*test_dt_interval, dt_column)\n",
    "        est = est.fit(\n",
    "            handle_nans(x.filter(training_interval).to_pandas()), \n",
    "            y.filter(training_interval).to_pandas()\n",
    "        )\n",
    "        x_test = x.filter(test_interval)\n",
    "        y_test = y.filter(test_interval)\n",
    "        #x_test = handle_nans(x.filter(test_interval).to_pandas())\n",
    "        #y_test = y.filter(test_interval).to_pandas()\n",
    "\n",
    "        for key, metric in metrics.items():\n",
    "            result_metrics[key].append(metric(x_test, y_test, est))\n",
    "        \n",
    "        estimators.append(est)\n",
    "\n",
    "    return result_metrics, estimators        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "cat_columns = categorical_columns.copy()\n",
    "cat_columns.remove('is_booking')\n",
    "train_data = x.drop('date_time')\n",
    "\n",
    "numerical_transform = Pipeline([\n",
    "    ('NumericalImputer', SimpleImputer(strategy='median', missing_values=np.nan)),\n",
    "    ('Scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_transform = Pipeline([\n",
    "    ('CategoricalImputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "base_pipeline = Pipeline([\n",
    "    (\n",
    "        'TransformingColumns',\n",
    "        ColumnTransformer([\n",
    "            ('Numerical', numerical_transform, numerical_columns),\n",
    "            ('Categorical', cat_transform, str_columns)\n",
    "        ])\n",
    "    ),\n",
    "    ('Logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "cluster_country = x.select('hotel_country', 'hotel_market', 'hotel_cluster')\n",
    "unique_values = cluster_country.unique()\n",
    "country_to_hotel_data = defaultdict(list)\n",
    "\n",
    "for row in unique_values.iter_rows():\n",
    "    country_to_hotel_data[row[0]].append(row[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.select('hotel_cluster', 'hotel_country').n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def accuracy(x_test: NDArray, y_test: NDArray, estimator: BaseEstimator) -> float:\n",
    "    return accuracy_score(y_test, estimator.predict(x_test))\n",
    "\n",
    "\n",
    "def sample_rows(row, columns: list[str], n: int) -> list[tuple]:\n",
    "    country_idx = columns.index('hotel_country')\n",
    "    market_idx = columns.index('hotel_market')\n",
    "    cluster_idx = columns.index('hotel_cluster')\n",
    "    country = row[country_idx]\n",
    "    result = [row]\n",
    "    i = 0\n",
    "    hd = country_to_hotel_data[country]\n",
    "    while len(result) < n and i < len(hd):\n",
    "        if hd[i] == (row[market_idx], row[cluster_idx]):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        row_copy = list(row)\n",
    "        row_copy[market_idx], row_copy[cluster_idx] = hd[i]\n",
    "        result.append(tuple(row_copy))\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def single_mrr(row: tuple, x_test: pl.DataFrame, \n",
    "               estimator: BaseEstimator, n: int = 5) -> float:\n",
    "    rows = sample_rows(row, x_test.columns, n)\n",
    "    rows = pl.DataFrame(\n",
    "        data={\n",
    "            col: [row[idx] for row in rows] for idx, col in enumerate(x_test.columns)\n",
    "        },\n",
    "        schema=x_test.schema\n",
    "    )\n",
    "    preds = list(estimator.predict_proba(rows.to_pandas())[:, 1].reshape(-1))\n",
    "    pred = preds[0]\n",
    "    preds.sort(reverse=True)\n",
    "    return 1 / (1 + preds.index(pred))\n",
    "\n",
    "\n",
    "def mrr(x_test: pl.DataFrame, y_test: pl.DataFrame, \n",
    "        estimator: BaseEstimator, n: int = 5) -> float:\n",
    "    x_test = x_test.filter(y_test)\n",
    "    result = 0\n",
    "    for row in x_test.iter_rows():\n",
    "        result += single_mrr(row, x_test, estimator, n) / len(x_test)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056c5ce497e94b22a5a6b2e03398100f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics, estimators = blocked_cross_validation(\n",
    "    x['date_time'].min(),\n",
    "    x['date_time'].max(),\n",
    "    timedelta(days=14),\n",
    "    timedelta(days=7),\n",
    "    base_pipeline,\n",
    "    x=x.drop('date_time'),\n",
    "    y=y,\n",
    "    dt_column=x['date_time'],\n",
    "    metrics={\n",
    "        'mrr': mrr\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magic-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
